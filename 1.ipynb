{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPs07/qlN1XKs21A94lxsV4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","import json\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","nltk.download('punkt')\n","\n","with open('/content/wocka.json','r') as f:\n","    temp=json.load(f)"],"metadata":{"id":"CCQTGpL5w2tk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HaO4xmttskK"},"outputs":[],"source":["jokes=list(map(lambda x: x['body'],temp))\n","jokes=list(map(lambda x: x.lower(),jokes)) #lowercase\n","\n","sentences=list()\n","for i in jokes:\n","x=sent_tokenize(i)\n","sentences.append(x)\n","\n","words=list()\n","for i in jokes:\n","    x=word_tokenize(i);\n","    words.append(x)"]},{"cell_type":"code","source":["nltk.download(\"stopwords\")\n","from nltk.corpus import stopwords\n","\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"id":"zQ-8Lz74wSVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stoplist=stopwords.words('english')\n","stoplist=set(stoplist)\n","words_filtered=list()\n","for i in words:\n","    x=[s for s in i if s not in stoplist]\n","    words_filtered.append(x)\n","\n","words_stem=list()\n","ps=PorterStemmer()\n","for i in words_filtered:\n","    x=[]\n","    for j in i:\n","        y=ps.stem(j)\n","        x.append(y)\n","    x=[w for w in x if w.isalnum()]\n","    words_stem.append(x)\n","\n","words_lem=list()\n","wl=WordNetLemmatizer()\n","for i in words_filtered:\n","    x=[]\n","    for j in i:\n","        j1=wl.lemmatize(j,pos='n')\n","        j2=wl.lemmatize(j1,pos='v')\n","        j3=wl.lemmatize(j2,pos='a')\n","        j4=wl.lemmatize(j3,pos='r')\n","        x.append(j4)\n","    y=[w for w in x if w.isalnum()]\n","    words_lem.append(y)"],"metadata":{"id":"DizoG3WnwDRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_inv_index(corpus: list):\n","    inv_index={}\n","    for docid,text in enumerate(corpus):\n","        for i in text:\n","            if i not in inv_index.keys():\n","                inv_index[i]=[docid]\n","            elif docid not in inv_index[i]:\n","                inv_index[i].append(docid)\n","    return inv_index\n","\n","inv_index=create_inv_index(words_lem)\n","sorted_terms=sorted(inv_index.keys())\n","final_inv_index={i : inv_index[i] for i in sorted_terms}"],"metadata":{"id":"iLMLl4fYv5Pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bool_and(l1,l2):\n","    result=[]\n","    for i in l1:\n","        if i in l2:\n","            result.append(i)\n","    return result\n","\n","def bool_or(l1,l2):\n","    result=[]\n","    for i in l1:\n","        result.append(i)\n","    for i in l2:\n","        if(i not in result):\n","            result.append(i)\n","    return result\n","\n","def bool_not(l1):\n","    result=[]\n","    for i in range(10019):\n","        if(i not in l1):\n","            result.append(i)\n","    return result\n","\n","l1=final_inv_index[\"cat\"]\n","l2=final_inv_index[\"car\"]\n","print(\"boolean and :\" , bool_and(l1,l2))\n","print(\"boolean or :\" , bool_or(l1,l2))\n","print(\"boolean not :\" , bool_not(l1))\n"],"metadata":{"id":"_XcJhX0yv1AP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_index={}\n","def create_pos_index(corpus: list):\n","    docno, lineno= 0, -1\n","    for doc in corpus:\n","        lineno += 1\n","        for pos,term in enumerate(doc):\n","            if term in pos_index:\n","                pos_index[term][0]=pos_index[term][0]+1\n","                if docno in pos_index[term][1]:\n","                    pos_index[term][1][lineno].append(pos)\n","                else:\n","                    pos_index[term][1][lineno]=[pos]\n","            else:\n","                pos_index[term]=[]\n","                pos_index[term].append(1)\n","                pos_index[term].append({})\n","                pos_index[term][1][lineno]=[pos]\n","        docno += 1\n","    return pos_index\n","\n","create_pos_index(words_lem)\n","sorted_terms=sorted(pos_index.keys())\n","final_pos_index={i : pos_index[i] for i in sorted_terms}\n"],"metadata":{"id":"QeTe1aj2vfys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge(l1,l2):\n","result=[]\n","    for d1 in l1[1].keys():\n","        if d1 in l2[1].keys():\n","            for i in l1[1][d1]:\n","                for j in l2[1][d1]:\n","                    if(i<j):\n","                        result.append(d1)\n","    return result\n","\n","def phrase_query():\n","    print(\"enter a phrase query\")\n","    phrase=input()\n","    phrase=list(phrase.split());\n","    result=[]\n","    for i in range(len(phrase)-1):\n","        l1=final_pos_index[phrase[i]]\n","        l2=final_pos_index[phrase[i+1]]\n","        temp=merge(l1,l2)\n","        if len(result):\n","            result=bool_and(result,temp)\n","        else:\n","            result = temp\n","    return result"],"metadata":{"id":"9JFqbVAHvHjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_permuterm_index(corpus):\n","    permuterm_index={}\n","    for doc in corpus:\n","        for term in doc:\n","            term += \"$\"\n","            for i in range(len(term)):\n","                permuterm=str(term[i:]+term[:i])\n","                if permuterm not in permuterm_index.keys():\n","                    permuterm_index[permuterm]=set()\n","                permuterm_index[permuterm].add(str(term[:-1]))\n","    return permuterm_index\n","\n","permuterm_index=create_permuterm_index(words_lem)"],"metadata":{"id":"P8Az01vavFwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def wildcard_query():\n","    print(\"enter a wildcard query\")\n","    wcquery=input()\n","    wcquery+=\"$\"\n","    if(wcquery[len(wcquery)-1]!='*'):\n","        for i in range(len(wcquery)):\n","            wcquery = str(wcquery[1:]+wcquery[:1])\n","            if wcquery[len(wcquery)-1] == '*':\n","                break\n","    for i in permuterm_index.keys():\n","        if i.startswith(str(wcquery[:-1])):\n","            print(list(permuterm_index.get(i))[0],final_inv_index[(list(permuterm_index.get(i))[0])])"],"metadata":{"id":"yI6kYSovvDgK"},"execution_count":null,"outputs":[]}]}